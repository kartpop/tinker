# Frontend
- custom scrollbar 
- change background theme from orange to white/transparent, keep orange highlights


# AI
- https://huggingface.co/datasets/bigdata-pw/Dinosaurs - source for structured dinosaur data

### Indexing pipeline
- Create embedder with metadata_fields_to_embed


### Adhoc tasks

# IDEAS

## Create complete manim explanatory videos using only a science concept text as input - PAUSED
- Test out LLM's capabilities in writing Manim code with few-shot learning
    - Create 3-5 example animations/diagrams in rigid body motion (say)
    - Prompt model to create a new animation/diagram in similar field to test how it works

- Idea
    - Create a corpus of 100s of example manim animation code snippets along with labelled metadata
        - Labelled metadata: detailed description of animation, each line of code has useful comments
    - When a concept is generated by LLM to explain a phenomenon:
        - feed the concept text to animator/diagramer agent
        - agent first performs semantic search to get the top_k relevant examples (animation code + description)
        - agent invokes LLM to prepare detailed plan for the animation using the top_k examples as context
        - agent then invokes LLM again to prepare final animation code
    - Postprocess
        - If the animation is satisfactory: what crietria to choose?? ask LLM again?
        - send diagram/animation to UI
        - save diagram/animation with description into vector database to add to the existing examples
    - Enhancement:
        - Create a custom finetuned model on animation data (once corpus reaches a few 10,000 datasets)


## Create manim videos iteratively using natural language - ABANDONED (already exists)
- Example: 'create a circle', 'make it a rigid body', 'apply a force on it from the left and let the animation play for 3 seconds', 'create a wall on the right', 'move it more to the right', 'run animation for 5 seconds'

- Steps
    - hand curate the above example
        - start with zero context to the LLM (assume initial instruction to be trivial)
        - on subsequent prompts, enrich context with appropriate low level instructions; for example, provide relevant code snippet when user instruction is 'apply a force on it from the left'
        - for starter, append the entire code till present instance as context along with above enriched context
            - later, think about how we can provide just the required code (not the entire file) along with low level instruction 

## Literature research assistant
- Use a local corpus of downloaded research papers of a specific topic to answer useful questions

- Stage 1:
    - General text, image, table, mathematical formula parsing to create index
    - Chat and artifacts panel in UI
        - artifacts panel can be used to display relevant images, tables (non plain-text) data from papers

- Stage 2:
    - Focus on a specific topic (say DNA nanotechnology or Molecular machines)
        - Make a narrow but very useful agent which does a bunch of tasks well in that specific domain using data from the papers